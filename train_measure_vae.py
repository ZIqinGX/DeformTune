import click
import torch
import os
import shutil
import numpy as np
import serial
import time
import pygame.midi

from torch.utils.data.dataset import TensorDataset
from MeasureVAE.measure_vae import MeasureVAE
from MeasureVAE.vae_trainer import VAETrainer
from MeasureVAE.vae_tester import VAETester
from data.dataloaders.bar_dataset import *
from utils.helpers import *

# âœ… ç¡®ä¿ PyTorch å¤šè¿›ç¨‹åˆå§‹åŒ–
if __name__ == '__main__':
    import torch.multiprocessing as mp
    mp.set_start_method('spawn', force=True)
    torch.serialization.add_safe_globals([TensorDataset])

print("âœ… æ­£åœ¨ä½¿ç”¨çš„ VAETrainer æ–‡ä»¶è·¯å¾„: MeasureVAE.vae_trainer")
print("PyTorchç‰ˆæœ¬:", torch.__version__)
print("CUDAæ˜¯å¦å¯ç”¨:", torch.cuda.is_available())
print("å½“å‰è®¾å¤‡:", torch.cuda.current_device())
print("è®¾å¤‡åç§°:", torch.cuda.get_device_name(0))

# âœ… åˆå§‹åŒ– Arduino è¿æ¥
try:
    arduino = serial.Serial('COM4', 9600, timeout=1)
    time.sleep(2)
    print("âœ… å·²è¿æ¥åˆ° Arduino")
except Exception as e:
    print(f"âš ï¸ æ— æ³•è¿æ¥åˆ° Arduino: {e}")
    arduino = None

# âœ… MIDI æ’­æ”¾å‡½æ•°

def play_midi(samples, debug=True):
    import pretty_midi

    midi = pretty_midi.PrettyMIDI()
    instrument = pretty_midi.Instrument(program=0)
    note_count = 0

    for i, note in enumerate(samples):
        pitch = int(note.item())
        if pitch <= 0 or pitch > 127:
            continue
        start_time = i * 0.5
        end_time = start_time + 0.5
        midi_note = pretty_midi.Note(velocity=100, pitch=pitch, start=start_time, end=end_time)
        instrument.notes.append(midi_note)
        note_count += 1

    midi.instruments.append(instrument)
    midi_file = "generated_debug.mid"
    midi.write(midi_file)

    if debug:
        print("ğŸ¼ å·²ä¿å­˜ MIDI æ–‡ä»¶: generated_debug.mid")
        print(f"ğŸ¹ å…±ç”Ÿæˆ {note_count} ä¸ªéŸ³ç¬¦")
        for note in instrument.notes:
            print(f"Pitch: {note.pitch}, Start: {note.start:.2f}, End: {note.end:.2f}")

    if note_count == 0:
        print("âš ï¸ æ— æœ‰æ•ˆéŸ³ç¬¦å¯æ’­æ”¾ï¼Œè·³è¿‡æ’­æ”¾ã€‚")
        return

    try:
        pygame.mixer.init()
        pygame.mixer.music.load(midi_file)
        pygame.mixer.music.play()
        print("ğŸµ æ­£åœ¨æ’­æ”¾...")
        while pygame.mixer.music.get_busy():
            time.sleep(0.1)
        print("âœ… æ’­æ”¾å®Œæˆ")
    except Exception as e:
        print(f"âš ï¸ æ’­æ”¾å¤±è´¥: {e}")

@click.command()
@click.option('--batch_size', default=256)
@click.option('--num_epochs', default=30)
@click.option('--train/--test', default=False)
def main(batch_size, num_epochs, train):
    print("âœ… è¿›å…¥ main() å‡½æ•°")
    print(f"[DEBUG] CLI å‚æ•°è§£ææˆåŠŸ: train = {train}, epochs = {num_epochs}")
    print(f"âš™ï¸ å½“å‰è¿è¡Œæ¨¡å¼: {'è®­ç»ƒ' if train else 'æµ‹è¯•'}")

    dataset_dir = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'datasets')
    if os.path.exists(dataset_dir):
        print("âš ï¸  å‘ç°æ—§æ•°æ®é›†ï¼Œåˆ é™¤ `datasets/` ç›®å½•...")
        shutil.rmtree(dataset_dir)
    os.makedirs(dataset_dir, exist_ok=True)

    print("ğŸ“… é‡æ–°åŠ è½½ `FolkNBarDataset` æ•°æ®é›†...")
    folk_dataset_train = FolkNBarDataset('train', is_short=True, num_bars=1)
    print(f"âœ… FolkNBarDataset Train loaded with {folk_dataset_train.num_dataset_files} files")
    folk_dataset_test = FolkNBarDataset('test', is_short=True, num_bars=1)
    print(f"âœ… FolkNBarDataset Test loaded with {folk_dataset_test.num_dataset_files} files")

    model = MeasureVAE(
        dataset=folk_dataset_train,
        note_embedding_dim=10,
        metadata_embedding_dim=2,
        num_encoder_layers=2,
        encoder_hidden_size=512,
        encoder_dropout_prob=0.5,
        latent_space_dim=256,
        num_decoder_layers=2,
        decoder_hidden_size=512,
        decoder_dropout_prob=0.5,
        has_metadata=False
    )

    model_path = "D:/PhD_Year1/Prototype1/Exploring_XAI_in_GenMus_via_LSR-main/Exploring_XAI_in_GenMus_via_LSR-main/MeasureVAE/models/MeasureVAE_4by4_FolkNBarDataset1__Encoder_512_Decoder_512.pt"
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    if os.path.exists(model_path) and not train:
        model.load_state_dict(torch.load(model_path, map_location=device))
        print(f"âœ… åŠ è½½æ¨¡å‹: {model_path}")

    model.to(device)

    if train:
        print("ğŸš€ è®­ç»ƒæ¨¡å¼å¯åŠ¨...")
        trainer = VAETrainer(
            dataset=folk_dataset_train,
            model=model,
            lr=1e-4,
            has_reg_loss=True,
            reg_type='rhy_complexity',
            reg_dim=0
        )
        print("ğŸ“¦ å‡†å¤‡å¯åŠ¨è®­ç»ƒæµç¨‹...")
        trainer.train_model(batch_size=batch_size, num_epochs=num_epochs, plot=True, log=True)
        print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆã€‚")
    else:
        print("ğŸ§ª æµ‹è¯•æ¨¡å¼å¯åŠ¨...")
        model.eval()
        tester = VAETester(
            dataset=folk_dataset_test,
            model=model,
            has_reg_loss=True,
            reg_type='rhy_complexity',
            reg_dim=0
        )
        print("ğŸ¯ è¯„ä¼°æ¨¡å‹...")
        tester.test_model(batch_size=batch_size)

        if arduino:
            print("ğŸ‡ å¼€å§‹å®æ—¶ç›‘å¬ Arduino è¾“å…¥...")
            while True:
                try:
                    raw = arduino.readline().decode().strip()
                    print(f"ğŸ—“ï¸ Arduino è¾“å…¥åŸå§‹å€¼: {raw}")
                    if not raw or 'å‡†å¤‡' in raw:
                        print(f"âš ï¸ è·³è¿‡æ— æ•ˆè¾“å…¥: {raw}")
                        continue
                    z0 = float(raw)
                    print(f"ğŸ›ï¸ è½¬æ¢å z0: {z0:.2f}")
                    z_tilde = torch.zeros(1, model.latent_space_dim).to(device)
                    z_tilde[0, 0] = z0
                    dummy_score_tensor = torch.zeros(1, 24).long().to(device)

                    with torch.no_grad():
                        _, samples = model.decoder(z_tilde, dummy_score_tensor, train=False)

                    print("ğŸ“‹ samples tensor shape:", samples.shape)
                    if samples.ndim == 3:
                        note_tensor = samples[0, 0].cpu()
                    elif samples.ndim == 2:
                        note_tensor = samples[0].cpu()
                    else:
                        note_tensor = samples.cpu()

                    print(f"ğŸ›ï¸ z0 = {z0:.2f} â†’ éŸ³ç¬¦åºåˆ—: {note_tensor.tolist()}")
                    play_midi(note_tensor, debug=True)

                except KeyboardInterrupt:
                    print("ğŸ›‘ ç»ˆæ­¢ç›‘å¬ã€‚")
                    break
                except Exception as e:
                    print(f"âš ï¸ é”™è¯¯: {e}")

if __name__ == '__main__':
    main()
